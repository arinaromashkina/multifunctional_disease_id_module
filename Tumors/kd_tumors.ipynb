{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9u29E2HlWLgKo0S2ompME"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install segmentation_models_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPGzDCoOD670","executionInfo":{"status":"ok","timestamp":1706362154264,"user_tz":-180,"elapsed":10095,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"fdba563c-4ec3-4585-b518-d2ce48eb7146"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation_models_pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.16.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation_models_pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=a59e588b46c997b18a91038e11031f199b6cd64121da7c52bfa9ea00c9cfe5b8\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=2cd07ccdd8de65ab188b6da57be10dfa77d37c5ac610789c6b4d6a87eb370f9a\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import segmentation_models_pytorch as smp\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import glob\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader\n","from torch.optim import AdamW\n","from torch.autograd import Variable\n","import torchvision\n","import pathlib\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision\n","from IPython.display import clear_output\n","from torch import nn, optim\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder"],"metadata":{"id":"vM9VrO4dEeOR","executionInfo":{"status":"ok","timestamp":1706362162754,"user_tz":-180,"elapsed":8493,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"h-PEafNcGpBX","executionInfo":{"status":"ok","timestamp":1706362162754,"user_tz":-180,"elapsed":11,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"a11978c5-cade-4289-a923-bc0f5c7eed0b"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYZDlSErFBus","executionInfo":{"status":"ok","timestamp":1706362211096,"user_tz":-180,"elapsed":36397,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"5df7c02d-e746-4441-e587-ec8147441841"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["test_path = '/content/drive/MyDrive/data_folder/Testing'\n","train_path = '/content/drive/MyDrive/data_folder/Training'"],"metadata":{"id":"x4amCdZ3FUz8","executionInfo":{"status":"ok","timestamp":1706362217524,"user_tz":-180,"elapsed":1418,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"0YkGBwWEFagf","executionInfo":{"status":"ok","timestamp":1706362219508,"user_tz":-180,"elapsed":1148,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_loader=DataLoader(\n","    torchvision.datasets.ImageFolder(train_path,transform=transform),\n","    batch_size=10, shuffle=True,\n",")\n","test_loader=DataLoader(\n","    torchvision.datasets.ImageFolder(test_path,transform=transform),\n","    batch_size=10, shuffle=True\n",")"],"metadata":{"id":"XJMK6VD7Fnlz","executionInfo":{"status":"ok","timestamp":1706362229405,"user_tz":-180,"elapsed":6882,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"J1UUVkd1Cos-","executionInfo":{"status":"ok","timestamp":1706362234095,"user_tz":-180,"elapsed":4,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"outputs":[],"source":["class ClassificationUnet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ClassificationUnet, self).__init__()\n","        self.unet = smp.Unet(encoder_name=\"efficientnet-b0\",\n","                             encoder_weights='imagenet',\n","                             in_channels=3,\n","                             classes=num_classes)\n","\n","    def forward(self, x):\n","        out = self.unet(x)\n","        out = torch.mean(out, dim=(2, 3))\n","        return out"]},{"cell_type":"code","source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.flat = nn.Flatten()\n","        self.fc = nn.Linear(32*26*26, num_classes)\n","        self.lsm = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        out = self.conv3(out)\n","        out = self.flat(out)\n","        out = nn.Flatten()(out)\n","        out = self.fc(out)\n","        out = self.lsm(out)\n","        return out"],"metadata":{"id":"Y2UUUtGiDmd0","executionInfo":{"status":"ok","timestamp":1706362240624,"user_tz":-180,"elapsed":10,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, epochs, learning_rate, device):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","    model.train()\n","    correct = 0\n","    total = 0\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            # inputs: A collection of batch_size images\n","            # labels: A vector of dimensionality batch_size with integers denoting class of each image\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes\n","            # labels: The actual labels of the images. Vector of dimensionality batch_size\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","        accuracy = 100 * correct / total\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}, Train Accuracy: {accuracy:.2f}%\")\n","\n","def test(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%\")\n","    return accuracy"],"metadata":{"id":"S9z3fOW2DnJt","executionInfo":{"status":"ok","timestamp":1706362248666,"user_tz":-180,"elapsed":2,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","nn_deep = ClassificationUnet(num_classes=4).to(device)\n","train(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device)\n","test_accuracy_deep = test(nn_deep, test_loader, device)\n","\n","\n","torch.manual_seed(42)\n","nn_light = ConvNet(num_classes=4).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezTquEH4GVFa","executionInfo":{"status":"ok","timestamp":1706363339717,"user_tz":-180,"elapsed":1037129,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"6f5d8d61-dfe3-439a-b10d-55776540890c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.6819150464719597, Train Accuracy: 74.15%\n","Epoch 2/10, Loss: 0.4021117304312227, Train Accuracy: 80.37%\n","Epoch 3/10, Loss: 0.28672241625937434, Train Accuracy: 83.64%\n","Epoch 4/10, Loss: 0.22432010613693384, Train Accuracy: 85.89%\n","Epoch 5/10, Loss: 0.14948914919976625, Train Accuracy: 87.75%\n","Epoch 6/10, Loss: 0.16271697595806384, Train Accuracy: 88.96%\n","Epoch 7/10, Loss: 0.13189708359234475, Train Accuracy: 89.87%\n","Epoch 8/10, Loss: 0.08454191673203057, Train Accuracy: 90.82%\n","Epoch 9/10, Loss: 0.06087676587008355, Train Accuracy: 91.63%\n","Epoch 10/10, Loss: 0.06179706558734438, Train Accuracy: 92.28%\n","Test Accuracy: 72.08%\n"]}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","new_nn_light = ConvNet(num_classes=4).to(device)"],"metadata":{"id":"S5HYZlwOIQwf","executionInfo":{"status":"ok","timestamp":1706363391921,"user_tz":-180,"elapsed":291,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","# Print the norm of the first layer of the initial lightweight model\n","print(\"Norm of 1st layer of nn_light:\", torch.norm(nn_light.conv1[0].weight).item())\n","# Print the norm of the first layer of the new lightweight model\n","print(\"Norm of 1st layer of new_nn_light:\", torch.norm(new_nn_light.conv1[0].weight).item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YmXVctDIe4F","executionInfo":{"status":"ok","timestamp":1706363539277,"user_tz":-180,"elapsed":5,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"4b38c168-2fb8-4400-c37a-2d6478635acd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Norm of 1st layer of nn_light: 1.6299890279769897\n","Norm of 1st layer of new_nn_light: 1.6299890279769897\n"]}]},{"cell_type":"code","source":["total_params_deep = \"{:,}\".format(sum(p.numel() for p in nn_deep.parameters()))\n","print(f\"DeepNN parameters: {total_params_deep}\")\n","total_params_light = \"{:,}\".format(sum(p.numel() for p in nn_light.parameters()))\n","print(f\"LightNN parameters: {total_params_light}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImzP_ivxMUxh","executionInfo":{"status":"ok","timestamp":1706363590563,"user_tz":-180,"elapsed":301,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"cd62dbc1-f411-4e56-9cbb-fe8d198d3322"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["DeepNN parameters: 6,251,904\n","LightNN parameters: 92,660\n"]}]},{"cell_type":"code","source":["train(nn_light, train_loader, epochs=10, learning_rate=0.001, device=device)\n","test_accuracy_light_ce = test(nn_light, test_loader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWszc-jBMjIM","executionInfo":{"status":"ok","timestamp":1706363871367,"user_tz":-180,"elapsed":246712,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"7880e49d-9f06-4bf2-d960-4a56b7223c82"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 1.553244510074941, Train Accuracy: 65.61%\n","Epoch 2/10, Loss: 0.6797848464564163, Train Accuracy: 73.00%\n","Epoch 3/10, Loss: 0.4533342053652952, Train Accuracy: 77.06%\n","Epoch 4/10, Loss: 0.2519062076166324, Train Accuracy: 80.55%\n","Epoch 5/10, Loss: 0.179424584004379, Train Accuracy: 83.07%\n","Epoch 6/10, Loss: 0.15291598078308835, Train Accuracy: 84.91%\n","Epoch 7/10, Loss: 0.10831541823414284, Train Accuracy: 86.55%\n","Epoch 8/10, Loss: 0.07427724054071465, Train Accuracy: 87.89%\n","Epoch 9/10, Loss: 0.06057847830693976, Train Accuracy: 89.01%\n","Epoch 10/10, Loss: 0.08535718605010924, Train Accuracy: 89.83%\n","Test Accuracy: 68.53%\n"]}]},{"cell_type":"code","source":["def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n","    ce_loss = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n","\n","    teacher.eval()  # Teacher set to evaluation mode\n","    student.train() # Student to train mode\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n","            with torch.no_grad():\n","                teacher_logits = teacher(inputs)\n","\n","            # Forward pass with the student model\n","            student_logits = student(inputs)\n","\n","            #Soften the student logits by applying softmax first and log() second\n","            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n","            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n","\n","            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n","            soft_targets_loss = -torch.sum(soft_targets * soft_prob) / soft_prob.size()[0] * (T**2)\n","\n","            # Calculate the true label loss\n","            label_loss = ce_loss(student_logits, labels)\n","\n","            # Weighted sum of the two losses\n","            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n","\n","# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n","train_knowledge_distillation(teacher=nn_deep, student=new_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n","test_accuracy_light_ce_and_kd = test(new_nn_light, test_loader, device)\n","\n","# Compare the student test accuracy with and without the teacher, after distillation\n","print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n","print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n","print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwnPbs9vN0Qk","executionInfo":{"status":"ok","timestamp":1706364502535,"user_tz":-180,"elapsed":335573,"user":{"displayName":"Арина Ромашкина","userId":"01466234959183828681"}},"outputId":"f3030de5-a47d-4371-d16d-e088e0f0c76f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 1.4755774104013675\n","Epoch 2/10, Loss: 0.96749778398238\n","Epoch 3/10, Loss: 0.7016602542757573\n","Epoch 4/10, Loss: 0.6019599178111512\n","Epoch 5/10, Loss: 0.5506074923359974\n","Epoch 6/10, Loss: 0.49105819613260676\n","Epoch 7/10, Loss: 0.4579504315549904\n","Epoch 8/10, Loss: 0.452589819759442\n","Epoch 9/10, Loss: 0.4408099041271708\n","Epoch 10/10, Loss: 0.41775742874120586\n","Test Accuracy: 73.10%\n","Teacher accuracy: 72.08%\n","Student accuracy without teacher: 68.53%\n","Student accuracy with CE + KD: 73.10%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"D4Bwzct9OgtT"},"execution_count":null,"outputs":[]}]}